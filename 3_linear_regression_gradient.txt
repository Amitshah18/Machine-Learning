import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import r2_score

salary_data = pd.read_csv("./salary_data.csv")
print(salary_data.head())

X = salary_data['YearsExperience'].values
y = salary_data['Salary'].values
X = X.reshape(-1, 1)
y = y.reshape(-1, 1)
theta0 = 0  # Intercept
theta1 = 0  # Slope
alpha = 0.01  # Learning Rate
epochs = 1000  # Number of Iterations
m = len(y)  # Number of data points

loss_history = []
for epoch in range(epochs):
    y_pred = theta0 + theta1 * X
    loss = (1/(2*m)) * np.sum((y_pred - y) ** 2)
    loss_history.append(loss)
    d_theta0 = (1/m) * np.sum(y_pred - y)
    d_theta1 = (1/m) * np.sum((y_pred - y) * X)
    theta0 -= alpha * d_theta0
    theta1 -= alpha * d_theta1
    if epoch % 100 == 0:
        print(f"Epoch {epoch}, Loss: {loss:.4f}")
print(f"Final Parameters: theta0 = {theta0:.4f}, theta1 = {theta1:.4f}")


plt.plot(range(epochs), loss_history, color='blue')
plt.xlabel("Epochs")
plt.ylabel("Loss (MSE)")
plt.title("Loss Curve for Gradient Descent")
plt.show()

plt.scatter(X, y, color='blue', label="Actual Data")
y_line = theta0 + theta1 * X
plt.plot(X, y_line, color='red', label="Regression Line")
plt.xlabel("Years of Experience")
plt.ylabel("Salary")
plt.title("Salary Prediction using Gradient Descent")
plt.legend()
plt.show()

y_pred_final = theta0 + theta1 * X
r2 = r2_score(y, y_pred_final)
print(f"RÂ² Score: {r2:.4f}")
